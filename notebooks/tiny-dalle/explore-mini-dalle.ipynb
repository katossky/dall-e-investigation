{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Exploration de mini Dall-E\n\n## 1. Comment les textes images & textes sont-ils pré-traités / encodés ?\n\nLe pré-traitement des textes et images sont répartis dans de nombreuses classes et fichiers Python. Essentiellement, il consiste à convertir le texte en une suite de tokens (des entiers qui représentent des catégories discrètes) avec `BartTokenizerFast` et à faire de même avec les images avec `VQModel`. Chacun de ces modèles possède en théorie un dictionnaire associé, qui associe à chaque token un vecteur dans $\\mathbb{R}^d$, construit de telle façon que la proximité entre deux vecteurs traduise une proximité entre les tokens correspondant. Contrairement à ce qu'une lecture trop rapide des articles de Dall-E et mini Dall-E pourrait laisser penser, ces vecteurs sont complètement ignorés. Les modèles doivent donc ré-apprendre la proxmité entre \"father\" et \"mother\" ou entre \"rose\" et \"roses\".\n\nDans le détail, voici les étapes du pré-traitement dans l'ordre de l'investigation:",
   "metadata": {
    "cell_id": "2d8a4e19-9bea-4bb1-a102-ff9a7544f34d",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b2c24c54-3178-4c47-803a-0fce6850df2e",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# dalle-mini/tools/train.py, lignes 539-544\n\ndataset.preprocess( # <------------------------------------------------ preprocess ?\n    tokenizer = tokenizer, # <----------------------------------------- tokenizer ?\n    decoder_start_token_id = model.config.decoder_start_token_id,\n    normalize_text = model.config.normalize_text,\n    max_length = model.config.max_text_length,\n)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "La recherche de `tokenizer` est la plus courte:",
   "metadata": {
    "cell_id": "feb3a095-acd3-4c07-9c16-339ab91d1e3a",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "ba54b635-3106-4ab3-8ad0-bbc045821cc4",
    "deepnote_cell_type": "code"
   },
   "source": "# dalle-mini/tools/train.py, lignes 488-492\n\n# load tokenizer\ntokenizer = DalleBartTokenizer.from_pretrained(\n    artifact_dir,\n    use_fast=True,\n)\n\n# dalle-mini/tools/train.py, ligne 49-54\n\nfrom dalle_mini.model import DalleBartTokenizer\n\n# dalle-mini/model/__init__.py, ligne 4\n\nfrom .tokenizer import DalleBartTokenizer\n\n# dalle-mini/model/tokenizer.py\n\n# En subtance:\n# DalleBartTokenizer = BartTokenizerFast + surcouche Weights and biases",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "La rechecherche de la méthode `preprocess()` est plus fastidieuse.",
   "metadata": {
    "cell_id": "a2502b8b-be25-4418-a785-7997a685c073",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "141e3288-dada-489d-b05a-17bdad8ea7e3",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# dalle-mini/src/dalle-mini/data.py, lignes 88 et suivantes\n# largement modifié par soucis de clarté\n\ndef preprocess(self, tokenizer, decoder_start_token_id, normalize_text, max_length):\n\n    def partial_preprocess_function = partial( # lignes 125-132\n        preprocess_function, # <----------------------------------- preprocess_function ?\n        tokenizer=tokenizer,\n        text_column=self.text_column, # <-------------------------- defaults to \"caption\"\n        encoding_column=self.encoding_column, # <------------------ defaults to \"embedding\"\n        max_length=max_length,\n        decoder_start_token_id=decoder_start_token_id,\n    )\n\n    # dalle-mini/src/dalle-mini/data.py, lignes 133-154, édité par soucis de clarté\n    ds = ds.map(partial_preprocess_function, batched=True) # <----- ds ?\n\n    # dalle-mini/src/dalle-mini/data.py, lignes 100-122, édité par soucis de clarté\n    ds = self.train_dataset # OU ds = self.eval_dataset\n\n# dalle-mini/src/dalle-mini/data.py, lignes 255-286, édité par soucis de clarté\n\ndef preprocess_function(\n    examples, # <--------------------------------------------------- examples = 1 element from ds\n    tokenizer,\n    text_column,\n    encoding_column,\n    max_length,\n    decoder_start_token_id,\n):\n    inputs = examples[text_column] # <------------------------------ this element must have \"caption\" \n\n    labels = examples[encoding_column] # <-------------------------- this element must have \"embedding\" \n    labels = np.asarray(labels)\n\n    model_inputs                      = tokenizer(inputs, ... )\n    model_inputs[\"labels\"]            = labels\n    model_inputs[\"decoder_input_ids\"] = shift_tokens_right(labels, decoder_start_token_id)\n    # shift_tokens_right() prepends the <bos> token and removes the last one\n\n    return model_inputs",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Maintenant reste à savoir comment ce `self.train_dataset` est constitué!",
   "metadata": {
    "cell_id": "5ed7dd1a-76aa-4b05-a8d9-e41d28a46a0e",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "56d5a218-ceb3-41fa-965f-15e606e29d3a",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# dalle-mini/tools/dataset/encode_dataset.ipynb, édité par soucis de clarté\n\n# pas de numéros de lignes :(\npd.DataFrame.from_dict(\n    {\"caption\": all_captions, \"encoding\": all_encoding} # <-------- all_captions ? all_encodings ?\n)\n\n# pas de numéros de lignes :(\nfor (images, captions) in dataloader :\n    images = images.numpy()\n    encoded = p_encode(images, vqgan_params) # <------------------- p_encode ?\n    encoded = encoded.reshape(-1, encoded.shape[-1])\n    all_captions.extend(captions)\n    all_encoding.extend(encoded.tolist())\n\n# pas de numéros de lignes :(\n@partial(jax.pmap, axis_name=\"batch\")\ndef p_encode(batch, params):\n    # Not sure if we should `replicate` params, does not seem to have any effect\n    _, indices = vqgan.encode(batch, params=params) # <------------ vqgan ?\n    return indices\n\n# pas de numéros de lignes :( \nvqgan = VQModel.from_pretrained(\"flax-community/vqgan_f16_16384\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Comment formater les tokens texte + image pour les passer à Bart?\n\n",
   "metadata": {
    "cell_id": "1fac9f32-3ebd-4fb7-a19e-5256c8508a74",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e808460a-c21e-4255-9ee3-74b478795778",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "def train_step(state, batch, ...): # <---------------------------- state object contains info about the\n#                                                                  current state of the model\n\n    def compute_loss(params, minibatch, dropout_rng): # <--------- minibatch is derived from batch\n        \n            minibatch, labels = minibatch.pop(\"labels\")\n            logits = state.apply_fn( # <-------------------------- apply_fn ?\n                **minibatch, .... # <----------------------------- minibatch ?\n            )[0]\n            return loss_fn(logits, labels)\n    \n    grad_fn = jax.value_and_grad(compute_loss)\n    # code continues to accumalate gradient accross the batch\n\n    # update state\n    loss, grads = loss_grad\n    state = state.apply_gradients(\n        grads=grads,\n        dropout_rng=dropout_rng,\n        train_time=state.train_time + delta_time,\n        train_samples=state.train_samples + batch_size_per_step,\n    )\n\n    metrics = {\n        \"loss\": loss,\n        \"learning_rate\": learning_rate_fn(state.step),\n    }\n\n    return state, metrics",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "What is this `apply_fn` method? And what do `minibatch`'s look like?",
   "metadata": {
    "cell_id": "954f0ec7-92f4-4848-a2d6-2a4ec03fe694",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "52cc9170-0aba-4355-baf2-0479983ad182",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# https://github.com/borisdayma/dalle-mini/blob/main/tools/train/train.py, lignes 708-714\ndef init_state( ... ):\n    return TrainState.create(\n        apply_fn = model.__call__,\n        ...\n    )\n\n# https://github.com/borisdayma/dalle-mini/blob/main/tools/train/train.py, lignes 493-509\nmodel = DalleBart(...)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "05eb8709-4be0-4a70-9889-95f0b8f913f6",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# minibatch comes from batch\n# I assume it has the same structure\n\ndef get_minibatch(batch, grad_idx):\n    return jax.tree_map(\n        lambda x: jax.lax.dynamic_index_in_dim(x, grad_idx, keepdims=False),\n        batch,\n    )\n\n# https://github.com/borisdayma/dalle-mini/blob/main/tools/train/train.py, lignes 1057-1063\n\nfor batch in train_loader: #  <--------------------------------------------- trainloader ?\n    \n    # ligne 1085\n    state, train_metrics = p_train_step(state, batch, delta_time) # <------- p_train_step ?\n\n# ligne \np_train_step = pjit(train_step, ...)\n\n# https://github.com/borisdayma/dalle-mini/blob/main/tools/train/train.py, lignes 1051-1055\n# train_loader is simply the whole dataset bit by bit\ntrain_loader = dataset.dataloader(\"train\")\n\n# le code de dataloader est ingérable :(\n# mais le plus gros du travail semble être fait ici\nfor idx in batch_idx:\n    batch = dataset[idx] # <------------------------------------------------- dataset ?\n    batch = {k: jnp.array(v) for k, v in batch.items()}\n    yield batch",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4f3692ed-5f27-49a4-899a-82a03e72232c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "253d809f-5e50-4a81-a326-80e49c3cacfe",
  "deepnote_execution_queue": []
 }
}